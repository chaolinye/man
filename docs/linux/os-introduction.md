# 操作系统导论

围绕三个主题

- virtualization(虚拟化)
    - 抽象
    - 机制
    - 策略
- concurrency(并发)
- persistence(持久性)

## 操作系统介绍

### 定位

操作系统的主要作用是让程序运行变得容易，允许程序共享内存，让程序能够与设备交互，以及其他类似的有趣的工作。

要做到这一点，操作系统主要利用虚拟化（virtualization）的技术。将物理（physical）资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。因此，我们有时将操作系统称为`虚拟机`。

另外操作系统需要提供了一些接口（API）让用户能够使用其功能（如运行程序、分配内存或访问文件）。典型的操作系统会提供几百个系统调用（system call），让应用程序调用。因此操作系统也被称为`标准库`。

最后，因为虚拟化让许多程序运行（从而共享CPU），让许多程序可以同时访问自己的指令和数据（从而共享内存），让许多程序访问设备（从而共享磁盘等），所以操作系统有时被称为`资源管理器`（resource manager）。

### 设计目标

操作系统的主要工作是

- 取得CPU、内存或磁盘等物理资源（resources），并对它们进行虚拟化（virtualize）
- 处理与并发（concurrency）有关的麻烦且棘手的问题
- 持久地（persistently）存储文件，从而使它们长期安

构建这样一个系统，要有一些目标，帮助我们集中设计和实现

一个最基本的目标，是**建立一些抽象**（abstraction），让系统方便和易于使用。抽象对我们在计算机科学中做的每件事都很有帮助。

另一个目标是**提供高性能**。换言之，我们的目标是最小化操作系统的开销（minimize the overhead）。

还有一个目标是在应用程序之间以及在 OS 和应用程序之间**提供保护**。

操作系统也必须不间断运行。当它失效时，系统上运行的所有应用程序也会失效。由于这种依赖性，操作系统往往力求**提供高度的可靠性**（reliability）

> 在许多操作系统中，一个通用的设计范式是将**高级策略**与其**低级机制**分开[。你可以将**机制看成为系统的“如何（how）”问题提供答案**。例如，操作系统如何执行上下文切换？**策略为“哪个（which）”问题提供答案**。例如，操作系统现在应该运行哪个进程?

### 简单历史

#### 早期操作系统：只是一些库

#### 超越库：保护

添加一些特殊的硬件指令和硬件状态，让向操作系统过渡变为更正式的、受控的过程。

系统调用和过程调用之间的关键区别在于，系统调用将控制转移（跳转）到OS中，同时提高硬件特权级别（hardware privilege level）。用户应用程序以所谓的用户模式（user mode）运行，这意味着硬件限制了应用程序的功能

#### 多道程序时代

主要是代表是 UNIX 操作系统。

注重内存保护

#### 个人计算机

## 虚拟化



## 虚拟化 CPU

关键问题：如何提供有许多 CPU 的假象？

操作系统通过虚拟化（virtualizing）CPU来提供这种假象。通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟CPU的假象。这就是时分共享（time sharing）CPU技术，允许用户如愿运行多个并发进程。潜在的开销就是性能损失，因为如果CPU必须共享，每个进程的运行就会慢一点。

### 抽象：进程

操作系统为正在运行的程序提供的抽象，就是所谓的进程（process）。也就是说，进程就是运行中的程序。

> 程序本身是没有生命周期的，它只是存在磁盘上面的一些指令（也可能是一些静态数据）。是操作系统让这些字节运行起来，让程序发挥作用。

为了理解构成进程的是什么，我们必须理解它的**机器状态**（machine state）：程序在运行时可以读取或更新的内容。

进程的机器状态有一个明显组成部分，就是它的内存。指令存在内存中。正在运行的程序读取和写入的数据也在内存中。因此进程可以访问的内存（称为**地址空间**，address space）是该进程的一部分。

进程的机器状态的另一部分是**寄存器**。许多指令明确地读取或更新寄存器，因此显然，它们对于执行该进程很重要。

有一些非常特殊的寄存器构成了该机器状态的一部分。例如，程序计数器（PC）告诉我们程序当前正在执行哪个指令；类似地，栈指针（stack pointer）和相关的帧指针（frame pointer）用于管理函数参数栈、局部变量和返回地址。

#### 进程创建的细节

![](../images/program_to_proc.png)

1. 将代码和所有静态数据（例如初始化变量）加载（load）到内存中，加载到进程的地址空间中。程序最初以某种可执行格式驻留在磁盘上

    > 现代操作系统惰性（lazily）执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载

2. 为程序的运行时栈（run-time stack或stack）分配一些内存。程序使用栈存放局部变量、函数参数和返回地址。操作系统也可能会用参数初始化栈。具体来说，它会将参数填入main()函数，即argc和argv数组。
3. 可能为程序的堆（heap）分配一些内存。堆用于显式请求的动态分配数据。起初堆会很小。随着程序运行，通过malloc()库API请求更多内存
4. 执行一些其他初始化任务。例如打开3个默认的文件描述符（标准输入、输出、错误）
5. 通过跳转到main()例程，OS将CPU的控制权转移到新创建的进程中，从而程序开始执行。

#### 进程状态

![](../images/process-state.png)

#### 数据结构

xv6 内核的 proc 结构

```c
// the registers will save and restore
// to stop and subsequently restart a process
// 上下文切换需要写入或者读取
struct context {
  int eip;
  int esp;
  int ebx;
  int ecx;
  int edx;
  int esi;
  int edi;
  int ebp;
};

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
                  RUNNABLE, RUNNING, ZOMBIE };

// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem;                   // Start of process memory
  uint sz;                     // Size of process memory
  char *kstack;                // Bottom of kernel stack
                               // for this process
  enum proc_state state;       // Process state
  int pid;                     // Process ID
  struct proc *parent;         // Parent process
  void *chan;                  // If non-zero, sleeping on chan
  int killed;                  // If non-zero, have been killed
  struct file *ofile[NOFILE];  // Open files
  struct inode *cwd;           // Current directory
  struct context context;      // Switch here to run process
  struct trapframe *tf;        // Trap frame for the
                               // current interrupt
};
```

#### 进程 API

`fork()`: 复制当前进程

> 父进程中返回码是子进程id，子进程中返回码是 0

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
    } else {             // parent goes down this path (main)
        printf("hello, I am parent of %d (pid:%d)\n",
                rc, (int) getpid());
    }
    return 0;
}
```

`wait()`/`waitpid()`: 等待子进程：

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int
main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
    } else {    // parent goes down this path (main)
        int wc = wait(NULL);
        printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
                rc, wc, (int) getpid());
    }
    return 0;
}
```

`exec()`: 让当前进程执行新程序

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int
main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup("wc");   // program: "wc" (word count)
        myargs[1] = strdup("p3.c"); // argument: file to count
        myargs[2] = NULL;          // marks end of array
        execvp(myargs[0], myargs); // runs word count
        printf("this shouldn't print out");
    } else {    // parent goes down this path (main)
        int wc = wait(NULL);
        printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
                rc, wc, (int) getpid());
    }
    return 0;
}
```

创建新进程 = `fork()` + `exec()`

事实证明，这种分离 `fork()` 及 `exec()` 的做法在构建 UNIX shell 的时候非常有用，因为这给了 shell 在 fork 之后 exec 之前运行代码的机会，这些代码可以在运行新程序前改变环境，从而让一系列有趣的功能很容易实现。


另外还可以通过 `kill()` 系统调用向进程发送信号（signal）


### 机制：受限直接执行

为了虚拟化CPU，操作系统需要以某种方式让许多任务共享物理CPU，让它们看起来像是同时运行。基本思想很简单：运行一个进程一段时间，然后运行另一个进程，如此轮换。通过以这种方式时分共享（time sharing）CPU，就实现了虚拟化。

这样的机制存在一些挑战：

1. 性能。如何在不增加系统开销的情况下实现虚拟化？
2. 控制权。如何有效地运行进程，同时保留对CPU的控制？控制权对于操作系统尤为重要，因为操作系统负责资源管理。如果没有控制权，一个进程可以简单地无限制运行并接管机器，或访问没有权限的信息。

#### 基本技巧：受限直接执行

为了使程序尽可能快地运行，操作系统开发人员想出了一种技术——我们称之为**受限的直接执行**（limited direct execution）。

> LDE 背后的想法很简单：让程序运行的大部分指令直接访问硬件，只在一些关键点（如进程发起系统调用或发生时钟中断）由操作系统介入来确保“在正确的时间，正确的地点，做正确的事”。

这个概念的“直接执行”部分很简单：只需直接在CPU上运行程序即可。

直接运行协议（无限制）

![](../images/direct-exec.png)

#### 问题1：受限制的操作

关键问题：如何执行受限制的操作？

一个进程必须能够执行I/O和其他一些受限制的操作，但又不能让进程完全控制系统。操作系统和硬件如何协作实现这一点？

硬件通过提供不同的执行模式来协助操作系统。在用户模式（user mode）下，应用程序不能完全访问硬件资源。在内核模式（kernel mode）下，操作系统可以访问机器的全部资源。还提供了陷入（trap）内核和从陷阱返回（return-from-trap）到用户模式程序的特别说明，以及一些指令，让操作系统告诉硬件陷阱表（trap table）在内存中的位置。

要执行系统调用，程序必须执行特殊的陷阱（trap）指令。该指令同时跳入内核并将特权级别提升到内核模式。完成后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，如你期望的那样，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

执行陷阱时，硬件需要小心，因为它必须确保存储足够的调用者寄存器，以便在操作系统发出从陷阱返回指令时能够正确返回。例如，在x86上，处理器会将程序计数器、标志和其他一些**寄存器推送到每个进程的内核栈**（kernel stack）上。从返回陷阱将从栈弹出这些值，并恢复执行用户模式程序。

系统调用过程：例如当你调用 `open()` 时，你正在执行对 C 库的过程调用。其中，无论是对于 open() 还是提供的其他系统调用，库都使用与内核一致的调用约定来将**参数**放在众所周知的位置（例如，在栈中或特定的寄存器中），将**系统调用号**也放入一个众所周知的位置（同样，放在栈或寄存器中），然后执行上述的陷阱指令。库中陷阱之后的代码准备好返回值，并将控制权返回给发出系统调用的程序。因此，C库中进行系统调用的部分是用汇编手工编码的，因为它们需要仔细遵循约定，以便正确处理参数和返回值，以及执行硬件特定的陷阱指令。

陷阱如何知道在OS内运行哪些代码？

内核通过在启动时设置**陷阱表（trap table）**来实现。当机器启动时，它在特权（内核）模式下执行，因此可以根据需要自由配置机器硬件。操作系统做的第一件事，就是告诉硬件在发生某些异常事件时要运行哪些代码。例如，当发生硬盘中断，发生键盘中断或程序进行系统调用时，应该运行哪些代码？操作系统通常通过某种特殊的指令，通知硬件这些陷阱处理程序的位置。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。

受限直接运行协议：

![](../images/limited-direct-exec.png)

#### 问题2：在程序之间切换

关键问题：如何重获CPU的控制权？

操作系统如何重新获得CPU的控制权（regain control），以便它可以在进程之间切换？

答案是：时钟中断（timer interrupt。时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序（interrupt handler）会运行。此时，操作系统重新获得CPU的控制权，因此可以做它想做的事：停止当前进程，并启动另一个进程。

受限直接执行协议（时钟中断）

![](../images/time-interrupt.png)

请注意，在此协议中，有**两种类型的寄存器保存/恢复**。第一种是发生时钟中断的时候。在这种情况下，运行进程的用户寄存器由硬件隐式保存，使用该进程的内核栈。第二种是当操作系统决定从A切换到B。在这种情况下，内核寄存器被软件（即OS）明确地保存，但这次被存储在该进程的进程结构的内存中。后一个操作让系统从好像刚刚由A陷入内核，变成好像刚刚由B陷入内核。

xv6的上下文切换代码:

```cpp
# void swtch(struct context **old, struct context *new);
#
# Save current register context in old
# and then load register context from new.
.globl swtch
swtch:
  # Save old registers
  movl 4(%esp), %eax # put old ptr into eax
  popl 0(%eax)        # save the old IP
  movl %esp, 4(%eax) # and stack
  movl %ebx, 8(%eax) # and other registers
  movl %ecx, 12(%eax)
  movl %edx, 16(%eax)
  movl %esi, 20(%eax)
  movl %edi, 24(%eax)
  movl %ebp, 28(%ea
  # Load new registers
  movl 4(%esp), %eax # put new ptr into eax
  movl 28(%eax), %ebp # restore other registers
  movl 24(%eax), %edi
  movl 20(%eax), %esi
  movl 16(%eax), %edx
  movl 12(%eax), %ecx
  movl 8(%eax), %ebx
  movl 4(%eax), %esp  # stack is switched here
  pushl 0(%eax)       # return addr put in place
  ret                 # finally return into new ctxt
```

!> 系统调用和上下文切换的性能：在具有2 GHz或3 GHz处理器的系统上的性能可以达到亚微秒级。

在系统调用期间发生时钟中断时会发生什么？

### 策略：进程调度

关键问题：如何开发调度策略？

我们该如何开发一个考虑调度策略的基本框架？什么是关键假设？哪些指标非常重要？哪些基本方法已经在早期的系统中使用？

#### 工作负载的假设

我们对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：
1．每一个工作运行相同的时间。
2．所有的工作同时到达。
3．一旦开始，每个工作保持运行直到完成。
4．所有的工作只是用CPU（即它们不执行IO操作）。
5．每个工作的运行时间是已知的。

#### 调度指标：周转时间

任务的周转时间：任务完成时间减去任务到达系统的时间。

#### 先进先出（FIFO）

存在护航效应：一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后

#### 最短任务优先（SJF）

在所有工作同时到达的假设，SJF 确实是一个最优调度算法

如果工作不是同时到达，长的任务先到，也会出现护航效应。

#### 最短完成时间优先（STCF）

向 SJF 添加抢占，称为最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First ，PSJF）调度程序。

在当前假设下（去掉第1， 2 个假设），STCF 是个最优秀的算法

#### 新的度量指标：响应时间

响应时间定义为从任务到达系统到首次运行的时间。

STCF和相关方法在响应时间上并不是很好。

如何构建对响应时间敏感的调度程序？

#### 轮转（RR）

轮转（Round-Robin，RR）调度：在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。

> 时间片长度必须是时钟中断周期的倍数

时间片长度对于RR是至关重要的。越短，RR在响应时间上表现越好。然而，时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者需要权衡时间片的长度，使其足够长，以便**摊销**（amortize）上下文切换成本，而又不会使系统不及时响应。

上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序运行时，它们在**CPU高速缓存、TLB、分支预测器和其他片上硬件**中建立了大量的状态。切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可能导致显著的性能成本

目前两种调度程序。第一种类型（SJF、STCF）优化周转时间，但对响应时间不利。第二种类型（RR）优化响应时间，但对周转时间不利。我们还有两个假设需要放宽：假设4（作业没有I/O）和假设5（每个作业的运行时间是已知的）。

#### 结合 I/O

STCF 调度中可以把有 I/O 的工作根据 I/O 的位置分为多个独立子工作，然后调度这些子工作。

#### 无法预知

我们介绍了调度的基本思想，并开发了两类方法。第一类是运行最短的工作，从而优化周转时间。第二类是交替运行所有工作，从而优化响应时间。

但是前面的所有调度都依赖于：知道每个工作的长度。真实情况下，操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个没有这种先验知识的SJF/STCF/RR？

### 调度：多级反馈队列（MLFQ）

关键问题：没有完备的知识如何调度？

没有工作长度的先验（priori）知识，如何设计一个能同时减少响应时间和周转时间的调度程序？

多级反馈队列（Multi-level Feedback Queue，MLFQ）是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术

MLFQ 中有许多独立的队列，每个队列有不同的优先级。任何时刻，一个工作只能存在于一个队列中。MLFQ总是优先执行较高优先级的工作（即在较高级队列中的工作）。

MLFQ调度策略的关键在于如何设置优先级。MLFQ 会根据观察到的行为跳转作用的优先级。例如，如果一个工作不断放弃CPU去等待键盘输入，这是交互型进程的可能行为，MLFQ因此会让它保持高优先级。相反，如果一个工作长时间地占用CPU，MLFQ会降低其优先级。

MLFQ的两条基本规则。

`规则1`: 如果A的优先级 > B的优先级，运行A（不运行B）。  
`规则2`: 如果A的优先级 = B的优先级，轮转运行A和B。


#### 尝试1：改变优先级

`规则3`: 工作进入系统时，放在最高优先级（最上层队列）   
规则4a: 工作用完整个时间片后，降低其优先级（移入下一个队列）。   
规则4b: 如果工作在其时间片以内主动释放CPU，则优先级不变。   

当前 MLFQ 的一些问题：

1. 饥饿问题：如果系统有“太多”交互型工作，就会不断占用CPU，导致长工作永远无法得到CPU
2. 愚弄调度程序：进程在时间片用完之前，调用一个I/O操作（比如访问一个无关的文件），从而主动释放CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。
3. 一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间表现为一个交互型的进程

#### 尝试2： 提升优先级

解决饥饿问题的一个简单的思路是周期性地提升（boost）所有工作的优先级

`规则5`: 经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

> S 的值应该如何设置？

#### 尝试3：更好的计时方式

解决愚弄调度程序。

`规则4`：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。

#### MLFQ 调优及其它问题

配置多少队列？每一层队列的时间片配置多大？

多久提升一次进程的优先级？

大多数的MLFQ变体都支持不同队列可变的时间片长度。高优先级队列通常只有较短的时间片（比如10ms或者更少），因而这一层的交互工作可以更快地切换。相反，低优先级队列中更多的是CPU密集型工作，配置更长的时间片会取得更好的效果

其他一些MLFQ调度程序没用表，甚至没用本章中讲到的规则，有些采用数学公式来调整优先级。例如，FreeBSD调度程序（4.3版本），会基于当前进程使用了多少CPU，通过公式计算某个工作的当前优先级。另外，使用量会随时间衰减，这提供了期望的优先级提升，

#### MLFQ 总结

MLFQ有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，MLFQ可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于SJF/STCF的很好的全局性能，同时对长时间运行的CPU密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的MLFQ作为自己的基础调度程序

### 调度：比例份额（彩票调度）

比例份额调度程序，有时也称为**公平份额调度程序**。

比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间。

比例份额调度程序有一个非常优秀的现代例子名为**彩票调度**

关键问题：如何按比例分配CPU？

如何设计调度程序来按比例分配CPU？其关键的机制是什么？效率如何？

#### 基本概念：彩票数表示份额

彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额

通过不断定时地（比如，每个时间片）抽取彩票，彩票调度从概率上（但不是确定的）获得这种份额比例。抽取彩票的过程很简单：调度程序知道总共的彩票数（在我们的例子中，有100张）。调度程序抽取中奖彩票，这是从0和99之间的一个数，拥有这个数对应的彩票的进程中奖。

> 彩票调度最精彩的地方在于利用了随机性。优点：简单、轻量、快

#### 如何分配彩票

假设用户自己知道如何分配，因此可以给每个用户一定量的彩票，由用户按照需要自主分配给自己的工作。然而这种方案似乎什么也没有解决——还是没有给出具体的分配策略。因此对于给定的一组工作，彩票分配的问题依然**没有最佳答案**。

#### 另一个公平分配算法：步长调度

随机方式可以使得调度程序的实现简单（且大致正确），但**偶尔并不能产生正确的比例**，尤其在工作运行时间很短的情况下。

步长调度是一个确定性的公平分配算法。

系统中的每个工作都有自己的步长，这个值与票数值成反比。在上面的例子中，A、B、C这3个工作的票数分别是100、50和250，我们通过用一个大数分别除以他们的票数来获得每个进程的步长。比如用10000除以这些票数值，得到了3个进程的步长分别为100、200和40。我们称这个值为每个进程的**步长**（stride）。每次进程运行后，我们会让它的计数器（称为**行程（pass）值**） 增加它的步长，记录它的总体进展。

当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长。

步长调度算法可以在每个调度周期后做到完全正确。

当然彩票调度有一个步长调度没有的优势——不需要**全局状态**。假如一个新的进程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成0吗？这样的话，它就独占CPU了。而彩票调度算法不需要对每个进程记录全局状态，只需要用新进程的票数更新全局的总票数就可以了。因此彩票调度算法能够更合理地处理新加入的进程。

### 多处理器调度

关键问题：如何在多处理器上调度工作

操作系统应该如何在多CPU上调度工作？会遇到什么新问题？已有的技术依旧适用吗？是否需要新的思路？

#### 多处理架构

多处理器的区别主要在于对硬件缓存（cache）的使用

> 缓存是基于局部性（locality）的概念，局部性有两种，即时间局部性和空间局部性

多处理器有各自的缓存，并共享同一个内存。这就存在**缓存一致性**问题。

硬件提供了这个问题的基本解决方案：通过**监控内存访问**，硬件可以保证获得正确的数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式是使用总线窥探。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU发现对它放在缓存中的数据的更新，会作废本地副本（从缓存中移除），或更新它（修改为新值）

多处理器调度的另一个问题是**缓存亲和度**。一个进程在某个CPU上运行时，会在该CPU的缓存中维护许多状态。下次该进程在相同CPU上运行时，由于缓存中的数据而执行得更快。相反，在不同的CPU上执行，会由于需要重新加载数据而很慢。

#### 单队列调度（SQMS）

单队列多处理器调度（SQMS）：简单地复用单处理器调度的基本架构，将所有需要调度的工作放入一个单独的队列中

优点：简单

短板：1. 扩展性差。访问调度队列需要加锁，性能损失大，处理器越多，性能越差。2. 缓存亲和性差

#### 多队列调度（MQMS）

在MQMS中，基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则，比如轮转或其他任何可能的算法。当一个工作进入系统后，系统会依照一些启发性规则（如随机或选择较空的队列）将其放入某个调度队列。这样一来，每个CPU调度之间相互独立，就避免了单队列的方式中由于数据共享及同步带来的问题。

新问题：如何应对负载不均

最明显的答案是让工作移动，这种技术我们称为迁移（migration）。通过工作的跨CPU迁移，可以真正实现负载均衡。

一个基本的方法是采用一种技术，名为**工作窃取**。通过这种方法，工作量较少的（源）队列不定期地“偷看”其他（目标）队列是不是比自己的工作多。如果目标队列比源队列（显著地）更满，就从目标队列“窃取”一个或多个工作，实现负载均衡。

那么间隔多长时间去检查呢？找到合适的阈值仍然是黑魔法，这在系统策略设计中很常见。

#### Linux 多处理器调度

存在3种不同的调度程序：`O(1)`调度程序、完全公平调度程序（`CFS`）以及BF调度程序（`BFS`）

`O(1)` 和 `CFS` 采用多队列，而 `BFS` 采用单队列，这说明两种方法都可以成功。当然它们之间还有很多不同的细节。例如，**O(1)调度程序是基于优先级的（类似于MLFQ）**，随时间推移改变进程的优先级，然后调度最高优先级进程，来实现各种调度目标。交互性得到了特别关注。与之不同，**CFS是确定的比例调度方法（类似于步长调度）**。**BFS作为3个算法中唯一采用单队列的算法，也基于比例调度**，但采用了更复杂的方案，称为最早最合适虚拟截止时间优先算法


## 虚拟化 内存

用户程序生成的每个地址都是虚拟地址。操作系统只是为每个进程提供一个假象，具体来说，就是它拥有自己的大量私有内存。在一些硬件帮助下，操作系统会将这些假的虚拟地址变成真实的物理地址，从而能够找到想要的信息。

### 抽象：地址空间

早期的操作系统内存分配（一次只能运行一个程序）

![](../images/os-memory0.png)

随着多道程序时代的到来，多道程序需要共享内存。

一种实现时分共享的方法，是让一个进程单独占用全部内存运行一小段时间（见图13.1），然后停止它，并将它所有的状态信息保存在磁盘上（包含所有的物理内存），加载其他进程的状态信息，再运行一段时间，这就实现了某种比较粗糙的机器共享。但是**这种方式太慢了**。

因此，在进程切换的时候，我们仍然将进程信息放在内存中，这样操作系统可以更有效率地实现时分共享。每个进程拥有一部分内存。

![](../images/os-memory1.png)

当多道程序同时驻留内存中，使**保护**（protection）成为重要问题。人们不希望一个进程可以读取其他进程的内存，更别说修改了。

因此操作系统需要提供一个易用的物理内存抽象。这个抽象叫作**地址空间**（address space），是运行的程序看到的系统中的内存

一个进程的地址空间包含运行的程序的所有内存状态（代码、静态数据、栈、堆）

> 堆（heap）用于管理动态分配的、用户管理的内存，C语言中调用 `malloc()` 或面向对象语言（如 C++ 或 Java）中调用 `new` 获得内存。

地址空间：

![](../images/os-memory2.png)

**关键问题：如何虚拟化内存**

操作系统如何在单一的物理内存上为多个运行的进程（所有进程共享内存）构建一个私有的、可能很大的地址空间的抽象？

例如当进程A尝试在地址0（虚拟地址）执行加载操作时，然而操作系统在硬件的支持下，出于某种原因，必须确保不是加载到物理地址0，而是物理地址320KB（这是A载入内存的地址）。这是内存虚拟化的关键。

> 隔离是建立可靠系统的关键原则。

虚拟内存系统的设计目标

- **透明**。让运行的程序不感知内存被虚拟化的事实
- **效率**。包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存来支持虚拟化）。为此引入了 TLB 硬件和多级页表设计。
- **保护**。当一个进程执行加载、存储或指令提取时，它不应该以任何方式访问或影响任何其他进程或操作系统本身的内存内容（即在它的地址空间之外的任何内容）

> 作为用户级程序的程序员，可以看到的任何地址都是虚拟地址。只有操作系统（和硬件）才知道物理地址。

### 内存操作 API

对于程序来说，有两种类型的内存。

- 栈（stack）内存，它的申请和释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。
- 堆（heap）内存，其中所有的申请和释放操作都由程序员显式地完成

C 程序通过 `void *malloc(size_t size)` 库函数申请堆内存：传入要申请的堆空间的大小，它成功就返回一个指向新申请空间的指针，失败就返回 NULL

事实证明，分配内存是等式的简单部分。知道何时、如何以及是否释放内存是困难的部分。要释放不再使用的堆内存，程序员只需调用 `free()`：

```c
int *x = malloc(10 * sizeof(int));
...
free(x);
```

!> 调用 free 函数时分配区域的大小不会被用户传入，必须由内存分配库本身记录追踪。

在使用malloc()和free()时会出现一些常见的错误。

1. 忘记分配内存

    ```c
    char *src = "hello";
    char *dst;        // oops! unallocated
    strcpy(dst, src); // segfault and die
    ```

2. 没有分配足够的内存

    ```c
    char *src = "hello";
    char *dst = (char *) malloc(strlen(src)); // too small!
    strcpy(dst, src); // work properly
    ```

3. 忘记初始化分配的内存
4. 忘记释放内存。称为内存泄漏。在这种情况下，当进程死亡时，操作系统才会清理其分配的所有页面

    > 系统中实际存在两级内存管理。第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或以其他方式结束）时将其回收。第二级管理在每个进程中，例如在调用 `malloc()` 和 `free()` 时，在堆内管理。因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题

5. 在用完之前释放内存。这种错误称为悬挂指针。随后的使用可能会导致程序崩溃或覆盖有效的内存（调用了 `free()`，但随后再次调用 `malloc()` 来分配其他内容）
6. 重复释放内存。未定义行为
7. 错误地调用 `free()`。传入一个无效的指针。

`malloc()` 和 `free()` 不是系统调用，而是库调用。malloc库管理虚拟地址空间内的空间，但是它本身是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求更多内存或者将一些内容释放回系统。

一个这样的**系统调用**叫作 `brk`，它被用来改变程序分断（break）的位置：堆结束的位置。它需要一个参数（新分断的地址），从而根据新分断是大于还是小于当前分断，来增加或减小堆的大小。另一个调用 `sbrk` 要求传入一个增量，但目的是类似的。

!> 请注意，你不应该直接调用brk或sbrk。它们被内存分配库使用.

还可以通过 `mmap()` 调用从操作系统获取内存。通过传入正确的参数，`mmap()` 可以在程序中创建一个匿名（anonymous）内存区域——这个区域不与任何特定文件相关联，而是与交换空间（swap space）相关联

另外，内存分配库还支持一些其他调用。例如，`calloc()` 分配内存，并在返回之前将其置零。`realloc()` 创建一个新的更大的内存区域，将旧区域复制到其中，并返回新区域的指针。

### 机制：地址转换

关键问题：如何高效、灵活地虚拟化内存

如何实现高效的内存虚拟化？如何提供应用程序所需的灵活性？如何保持控制应用程序可访问的内存位置，从而确保应用程序的内存访问受到合理的限制？如何高效地实现这一切？

我们利用了一种通用技术，有时被称为基于硬件的地址转换，简称为**地址转换**（address translation)。利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写入），将指令中的虚拟地址转换为数据实际存储的物理地址。因此，在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际的位置。

当然，仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。因此它必须管理内存，记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对内存使用的控制。

所有这些工作都是为了创造一种美丽的假象：每个程序都拥有私有的内存，那里存放着它自己的代码和数据。

#### 动态（基于硬件）重定位




#### 分段



#### 空闲空间管理

#### 分页

#### 分页：快速地址转换（TLB）

#### 分页：较小的表

### 超越物理内存：机制

### 超越物理内存：策略

### VAX/VMS 虚拟内存系统

## 并发