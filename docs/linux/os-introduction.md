# 操作系统导论

围绕三个主题

- virtualization(虚拟化)
    - 抽象
    - 机制
    - 策略
- concurrency(并发)
- persistence(持久性)

## 操作系统介绍

### 定位

操作系统的主要作用是让程序运行变得容易，允许程序共享内存，让程序能够与设备交互，以及其他类似的有趣的工作。

要做到这一点，操作系统主要利用虚拟化（virtualization）的技术。将物理（physical）资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。因此，我们有时将操作系统称为`虚拟机`。

另外操作系统需要提供了一些接口（API）让用户能够使用其功能（如运行程序、分配内存或访问文件）。典型的操作系统会提供几百个系统调用（system call），让应用程序调用。因此操作系统也被称为`标准库`。

最后，因为虚拟化让许多程序运行（从而共享CPU），让许多程序可以同时访问自己的指令和数据（从而共享内存），让许多程序访问设备（从而共享磁盘等），所以操作系统有时被称为`资源管理器`（resource manager）。

### 设计目标

操作系统的主要工作是

- 取得CPU、内存或磁盘等物理资源（resources），并对它们进行虚拟化（virtualize）
- 处理与并发（concurrency）有关的麻烦且棘手的问题
- 持久地（persistently）存储文件，从而使它们长期安

构建这样一个系统，要有一些目标，帮助我们集中设计和实现

一个最基本的目标，是**建立一些抽象**（abstraction），让系统方便和易于使用。抽象对我们在计算机科学中做的每件事都很有帮助。

另一个目标是**提供高性能**。换言之，我们的目标是最小化操作系统的开销（minimize the overhead）。

还有一个目标是在应用程序之间以及在 OS 和应用程序之间**提供保护**。

操作系统也必须不间断运行。当它失效时，系统上运行的所有应用程序也会失效。由于这种依赖性，操作系统往往力求**提供高度的可靠性**（reliability）

> 在许多操作系统中，一个通用的设计范式是将**高级策略**与其**低级机制**分开[。你可以将**机制看成为系统的“如何（how）”问题提供答案**。例如，操作系统如何执行上下文切换？**策略为“哪个（which）”问题提供答案**。例如，操作系统现在应该运行哪个进程?

### 简单历史

#### 早期操作系统：只是一些库

#### 超越库：保护

添加一些特殊的硬件指令和硬件状态，让向操作系统过渡变为更正式的、受控的过程。

系统调用和过程调用之间的关键区别在于，系统调用将控制转移（跳转）到OS中，同时提高硬件特权级别（hardware privilege level）。用户应用程序以所谓的用户模式（user mode）运行，这意味着硬件限制了应用程序的功能

#### 多道程序时代

主要是代表是 UNIX 操作系统。

注重内存保护

#### 个人计算机

## 虚拟化



## 虚拟化 CPU

关键问题：如何提供有许多 CPU 的假象？

操作系统通过虚拟化（virtualizing）CPU来提供这种假象。通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟CPU的假象。这就是时分共享（time sharing）CPU技术，允许用户如愿运行多个并发进程。潜在的开销就是性能损失，因为如果CPU必须共享，每个进程的运行就会慢一点。

### 抽象：进程

操作系统为正在运行的程序提供的抽象，就是所谓的进程（process）。也就是说，进程就是运行中的程序。

> 程序本身是没有生命周期的，它只是存在磁盘上面的一些指令（也可能是一些静态数据）。是操作系统让这些字节运行起来，让程序发挥作用。

为了理解构成进程的是什么，我们必须理解它的**机器状态**（machine state）：程序在运行时可以读取或更新的内容。

进程的机器状态有一个明显组成部分，就是它的内存。指令存在内存中。正在运行的程序读取和写入的数据也在内存中。因此进程可以访问的内存（称为**地址空间**，address space）是该进程的一部分。

进程的机器状态的另一部分是**寄存器**。许多指令明确地读取或更新寄存器，因此显然，它们对于执行该进程很重要。

有一些非常特殊的寄存器构成了该机器状态的一部分。例如，程序计数器（PC）告诉我们程序当前正在执行哪个指令；类似地，栈指针（stack pointer）和相关的帧指针（frame pointer）用于管理函数参数栈、局部变量和返回地址。

#### 进程创建的细节

![](../images/program_to_proc.png)

1. 将代码和所有静态数据（例如初始化变量）加载（load）到内存中，加载到进程的地址空间中。程序最初以某种可执行格式驻留在磁盘上

    > 现代操作系统惰性（lazily）执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载

2. 为程序的运行时栈（run-time stack或stack）分配一些内存。程序使用栈存放局部变量、函数参数和返回地址。操作系统也可能会用参数初始化栈。具体来说，它会将参数填入main()函数，即argc和argv数组。
3. 可能为程序的堆（heap）分配一些内存。堆用于显式请求的动态分配数据。起初堆会很小。随着程序运行，通过malloc()库API请求更多内存
4. 执行一些其他初始化任务。例如打开3个默认的文件描述符（标准输入、输出、错误）
5. 通过跳转到main()例程，OS将CPU的控制权转移到新创建的进程中，从而程序开始执行。

#### 进程状态

![](../images/process-state.png)

#### 数据结构

xv6 内核的 proc 结构

```c
// the registers will save and restore
// to stop and subsequently restart a process
// 上下文切换需要写入或者读取
struct context {
  int eip;
  int esp;
  int ebx;
  int ecx;
  int edx;
  int esi;
  int edi;
  int ebp;
};

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
                  RUNNABLE, RUNNING, ZOMBIE };

// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem;                   // Start of process memory
  uint sz;                     // Size of process memory
  char *kstack;                // Bottom of kernel stack
                               // for this process
  enum proc_state state;       // Process state
  int pid;                     // Process ID
  struct proc *parent;         // Parent process
  void *chan;                  // If non-zero, sleeping on chan
  int killed;                  // If non-zero, have been killed
  struct file *ofile[NOFILE];  // Open files
  struct inode *cwd;           // Current directory
  struct context context;      // Switch here to run process
  struct trapframe *tf;        // Trap frame for the
                               // current interrupt
};
```

#### 进程 API

`fork()`: 复制当前进程

> 父进程中返回码是子进程id，子进程中返回码是 0

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
    } else {             // parent goes down this path (main)
        printf("hello, I am parent of %d (pid:%d)\n",
                rc, (int) getpid());
    }
    return 0;
}
```

`wait()`/`waitpid()`: 等待子进程：

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int
main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
    } else {    // parent goes down this path (main)
        int wc = wait(NULL);
        printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
                rc, wc, (int) getpid());
    }
    return 0;
}
```

`exec()`: 让当前进程执行新程序

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int
main(int argc, char *argv[])
{
    printf("hello world (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) {        // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("hello, I am child (pid:%d)\n", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup("wc");   // program: "wc" (word count)
        myargs[1] = strdup("p3.c"); // argument: file to count
        myargs[2] = NULL;          // marks end of array
        execvp(myargs[0], myargs); // runs word count
        printf("this shouldn't print out");
    } else {    // parent goes down this path (main)
        int wc = wait(NULL);
        printf("hello, I am parent of %d (wc:%d) (pid:%d)\n",
                rc, wc, (int) getpid());
    }
    return 0;
}
```

创建新进程 = `fork()` + `exec()`

事实证明，这种分离 `fork()` 及 `exec()` 的做法在构建 UNIX shell 的时候非常有用，因为这给了 shell 在 fork 之后 exec 之前运行代码的机会，这些代码可以在运行新程序前改变环境，从而让一系列有趣的功能很容易实现。


另外还可以通过 `kill()` 系统调用向进程发送信号（signal）


### 机制：受限直接执行

为了虚拟化CPU，操作系统需要以某种方式让许多任务共享物理CPU，让它们看起来像是同时运行。基本思想很简单：运行一个进程一段时间，然后运行另一个进程，如此轮换。通过以这种方式时分共享（time sharing）CPU，就实现了虚拟化。

这样的机制存在一些挑战：

1. 性能。如何在不增加系统开销的情况下实现虚拟化？
2. 控制权。如何有效地运行进程，同时保留对CPU的控制？控制权对于操作系统尤为重要，因为操作系统负责资源管理。如果没有控制权，一个进程可以简单地无限制运行并接管机器，或访问没有权限的信息。

#### 基本技巧：受限直接执行

为了使程序尽可能快地运行，操作系统开发人员想出了一种技术——我们称之为**受限的直接执行**（limited direct execution）。

> LDE 背后的想法很简单：让程序运行的大部分指令直接访问硬件，只在一些关键点（如进程发起系统调用或发生时钟中断）由操作系统介入来确保“在正确的时间，正确的地点，做正确的事”。

这个概念的“直接执行”部分很简单：只需直接在CPU上运行程序即可。

直接运行协议（无限制）

![](../images/direct-exec.png)

#### 问题1：受限制的操作

关键问题：如何执行受限制的操作？

一个进程必须能够执行I/O和其他一些受限制的操作，但又不能让进程完全控制系统。操作系统和硬件如何协作实现这一点？

硬件通过提供不同的执行模式来协助操作系统。在用户模式（user mode）下，应用程序不能完全访问硬件资源。在内核模式（kernel mode）下，操作系统可以访问机器的全部资源。还提供了陷入（trap）内核和从陷阱返回（return-from-trap）到用户模式程序的特别说明，以及一些指令，让操作系统告诉硬件陷阱表（trap table）在内存中的位置。

要执行系统调用，程序必须执行特殊的陷阱（trap）指令。该指令同时跳入内核并将特权级别提升到内核模式。完成后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，如你期望的那样，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

执行陷阱时，硬件需要小心，因为它必须确保存储足够的调用者寄存器，以便在操作系统发出从陷阱返回指令时能够正确返回。例如，在x86上，处理器会将程序计数器、标志和其他一些**寄存器推送到每个进程的内核栈**（kernel stack）上。从返回陷阱将从栈弹出这些值，并恢复执行用户模式程序。

系统调用过程：例如当你调用 `open()` 时，你正在执行对 C 库的过程调用。其中，无论是对于 open() 还是提供的其他系统调用，库都使用与内核一致的调用约定来将**参数**放在众所周知的位置（例如，在栈中或特定的寄存器中），将**系统调用号**也放入一个众所周知的位置（同样，放在栈或寄存器中），然后执行上述的陷阱指令。库中陷阱之后的代码准备好返回值，并将控制权返回给发出系统调用的程序。因此，C库中进行系统调用的部分是用汇编手工编码的，因为它们需要仔细遵循约定，以便正确处理参数和返回值，以及执行硬件特定的陷阱指令。

陷阱如何知道在OS内运行哪些代码？

内核通过在启动时设置**陷阱表（trap table）**来实现。当机器启动时，它在特权（内核）模式下执行，因此可以根据需要自由配置机器硬件。操作系统做的第一件事，就是告诉硬件在发生某些异常事件时要运行哪些代码。例如，当发生硬盘中断，发生键盘中断或程序进行系统调用时，应该运行哪些代码？操作系统通常通过某种特殊的指令，通知硬件这些陷阱处理程序的位置。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。

受限直接运行协议：

![](../images/limited-direct-exec.png)

#### 问题2：在程序之间切换

关键问题：如何重获CPU的控制权？

操作系统如何重新获得CPU的控制权（regain control），以便它可以在进程之间切换？

答案是：时钟中断（timer interrupt。时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序（interrupt handler）会运行。此时，操作系统重新获得CPU的控制权，因此可以做它想做的事：停止当前进程，并启动另一个进程。

受限直接执行协议（时钟中断）

![](../images/time-interrupt.png)

请注意，在此协议中，有**两种类型的寄存器保存/恢复**。第一种是发生时钟中断的时候。在这种情况下，运行进程的用户寄存器由硬件隐式保存，使用该进程的内核栈。第二种是当操作系统决定从A切换到B。在这种情况下，内核寄存器被软件（即OS）明确地保存，但这次被存储在该进程的进程结构的内存中。后一个操作让系统从好像刚刚由A陷入内核，变成好像刚刚由B陷入内核。

xv6的上下文切换代码:

```cpp
# void swtch(struct context **old, struct context *new);
#
# Save current register context in old
# and then load register context from new.
.globl swtch
swtch:
  # Save old registers
  movl 4(%esp), %eax # put old ptr into eax
  popl 0(%eax)        # save the old IP
  movl %esp, 4(%eax) # and stack
  movl %ebx, 8(%eax) # and other registers
  movl %ecx, 12(%eax)
  movl %edx, 16(%eax)
  movl %esi, 20(%eax)
  movl %edi, 24(%eax)
  movl %ebp, 28(%ea
  # Load new registers
  movl 4(%esp), %eax # put new ptr into eax
  movl 28(%eax), %ebp # restore other registers
  movl 24(%eax), %edi
  movl 20(%eax), %esi
  movl 16(%eax), %edx
  movl 12(%eax), %ecx
  movl 8(%eax), %ebx
  movl 4(%eax), %esp  # stack is switched here
  pushl 0(%eax)       # return addr put in place
  ret                 # finally return into new ctxt
```

!> 系统调用和上下文切换的性能：在具有2 GHz或3 GHz处理器的系统上的性能可以达到亚微秒级。

在系统调用期间发生时钟中断时会发生什么？

### 策略：进程调度

关键问题：如何开发调度策略？

我们该如何开发一个考虑调度策略的基本框架？什么是关键假设？哪些指标非常重要？哪些基本方法已经在早期的系统中使用？

#### 工作负载的假设

我们对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：
1．每一个工作运行相同的时间。
2．所有的工作同时到达。
3．一旦开始，每个工作保持运行直到完成。
4．所有的工作只是用CPU（即它们不执行IO操作）。
5．每个工作的运行时间是已知的。

#### 调度指标：周转时间

任务的周转时间：任务完成时间减去任务到达系统的时间。

#### 先进先出（FIFO）

存在护航效应：一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后

#### 最短任务优先（SJF）

在所有工作同时到达的假设，SJF 确实是一个最优调度算法

如果工作不是同时到达，长的任务先到，也会出现护航效应。

#### 最短完成时间优先（STCF）

向 SJF 添加抢占，称为最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First ，PSJF）调度程序。

在当前假设下（去掉第1， 2 个假设），STCF 是个最优秀的算法

#### 新的度量指标：响应时间

响应时间定义为从任务到达系统到首次运行的时间。

STCF和相关方法在响应时间上并不是很好。

如何构建对响应时间敏感的调度程序？

#### 轮转（RR）

轮转（Round-Robin，RR）调度：在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。

> 时间片长度必须是时钟中断周期的倍数

时间片长度对于RR是至关重要的。越短，RR在响应时间上表现越好。然而，时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者需要权衡时间片的长度，使其足够长，以便**摊销**（amortize）上下文切换成本，而又不会使系统不及时响应。

上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序运行时，它们在**CPU高速缓存、TLB、分支预测器和其他片上硬件**中建立了大量的状态。切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可能导致显著的性能成本

目前两种调度程序。第一种类型（SJF、STCF）优化周转时间，但对响应时间不利。第二种类型（RR）优化响应时间，但对周转时间不利。我们还有两个假设需要放宽：假设4（作业没有I/O）和假设5（每个作业的运行时间是已知的）。

#### 结合 I/O

STCF 调度中可以把有 I/O 的工作根据 I/O 的位置分为多个独立子工作，然后调度这些子工作。

#### 无法预知

我们介绍了调度的基本思想，并开发了两类方法。第一类是运行最短的工作，从而优化周转时间。第二类是交替运行所有工作，从而优化响应时间。

但是前面的所有调度都依赖于：知道每个工作的长度。真实情况下，操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个没有这种先验知识的SJF/STCF/RR？

### 调度：多级反馈队列（MLFQ）

关键问题：没有完备的知识如何调度？

没有工作长度的先验（priori）知识，如何设计一个能同时减少响应时间和周转时间的调度程序？

多级反馈队列（Multi-level Feedback Queue，MLFQ）是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术

MLFQ 中有许多独立的队列，每个队列有不同的优先级。任何时刻，一个工作只能存在于一个队列中。MLFQ总是优先执行较高优先级的工作（即在较高级队列中的工作）。

MLFQ调度策略的关键在于如何设置优先级。MLFQ 会根据观察到的行为跳转作用的优先级。例如，如果一个工作不断放弃CPU去等待键盘输入，这是交互型进程的可能行为，MLFQ因此会让它保持高优先级。相反，如果一个工作长时间地占用CPU，MLFQ会降低其优先级。

MLFQ的两条基本规则。

`规则1`: 如果A的优先级 > B的优先级，运行A（不运行B）。  
`规则2`: 如果A的优先级 = B的优先级，轮转运行A和B。


#### 尝试1：改变优先级

`规则3`: 工作进入系统时，放在最高优先级（最上层队列）   
规则4a: 工作用完整个时间片后，降低其优先级（移入下一个队列）。   
规则4b: 如果工作在其时间片以内主动释放CPU，则优先级不变。   

当前 MLFQ 的一些问题：

1. 饥饿问题：如果系统有“太多”交互型工作，就会不断占用CPU，导致长工作永远无法得到CPU
2. 愚弄调度程序：进程在时间片用完之前，调用一个I/O操作（比如访问一个无关的文件），从而主动释放CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。
3. 一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间表现为一个交互型的进程

#### 尝试2： 提升优先级

解决饥饿问题的一个简单的思路是周期性地提升（boost）所有工作的优先级

`规则5`: 经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

> S 的值应该如何设置？

#### 尝试3：更好的计时方式

解决愚弄调度程序。

`规则4`：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。

#### MLFQ 调优及其它问题

配置多少队列？每一层队列的时间片配置多大？

多久提升一次进程的优先级？

大多数的MLFQ变体都支持不同队列可变的时间片长度。高优先级队列通常只有较短的时间片（比如10ms或者更少），因而这一层的交互工作可以更快地切换。相反，低优先级队列中更多的是CPU密集型工作，配置更长的时间片会取得更好的效果

其他一些MLFQ调度程序没用表，甚至没用本章中讲到的规则，有些采用数学公式来调整优先级。例如，FreeBSD调度程序（4.3版本），会基于当前进程使用了多少CPU，通过公式计算某个工作的当前优先级。另外，使用量会随时间衰减，这提供了期望的优先级提升，

#### MLFQ 总结

MLFQ有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，MLFQ可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于SJF/STCF的很好的全局性能，同时对长时间运行的CPU密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的MLFQ作为自己的基础调度程序

### 调度：比例份额（彩票调度）

比例份额调度程序，有时也称为**公平份额调度程序**。

比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间。

比例份额调度程序有一个非常优秀的现代例子名为**彩票调度**

关键问题：如何按比例分配CPU？

如何设计调度程序来按比例分配CPU？其关键的机制是什么？效率如何？

#### 基本概念：彩票数表示份额

彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额

通过不断定时地（比如，每个时间片）抽取彩票，彩票调度从概率上（但不是确定的）获得这种份额比例。抽取彩票的过程很简单：调度程序知道总共的彩票数（在我们的例子中，有100张）。调度程序抽取中奖彩票，这是从0和99之间的一个数，拥有这个数对应的彩票的进程中奖。

> 彩票调度最精彩的地方在于利用了随机性。优点：简单、轻量、快

#### 如何分配彩票

假设用户自己知道如何分配，因此可以给每个用户一定量的彩票，由用户按照需要自主分配给自己的工作。然而这种方案似乎什么也没有解决——还是没有给出具体的分配策略。因此对于给定的一组工作，彩票分配的问题依然**没有最佳答案**。

#### 另一个公平分配算法：步长调度

随机方式可以使得调度程序的实现简单（且大致正确），但**偶尔并不能产生正确的比例**，尤其在工作运行时间很短的情况下。

步长调度是一个确定性的公平分配算法。

系统中的每个工作都有自己的步长，这个值与票数值成反比。在上面的例子中，A、B、C这3个工作的票数分别是100、50和250，我们通过用一个大数分别除以他们的票数来获得每个进程的步长。比如用10000除以这些票数值，得到了3个进程的步长分别为100、200和40。我们称这个值为每个进程的**步长**（stride）。每次进程运行后，我们会让它的计数器（称为**行程（pass）值**） 增加它的步长，记录它的总体进展。

当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长。

步长调度算法可以在每个调度周期后做到完全正确。

当然彩票调度有一个步长调度没有的优势——不需要**全局状态**。假如一个新的进程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成0吗？这样的话，它就独占CPU了。而彩票调度算法不需要对每个进程记录全局状态，只需要用新进程的票数更新全局的总票数就可以了。因此彩票调度算法能够更合理地处理新加入的进程。

### 多处理器调度

关键问题：如何在多处理器上调度工作

操作系统应该如何在多CPU上调度工作？会遇到什么新问题？已有的技术依旧适用吗？是否需要新的思路？

#### 多处理架构

多处理器的区别主要在于对硬件缓存（cache）的使用

> 缓存是基于局部性（locality）的概念，局部性有两种，即时间局部性和空间局部性

多处理器有各自的缓存，并共享同一个内存。这就存在**缓存一致性**问题。

硬件提供了这个问题的基本解决方案：通过**监控内存访问**，硬件可以保证获得正确的数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式是使用总线窥探。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU发现对它放在缓存中的数据的更新，会作废本地副本（从缓存中移除），或更新它（修改为新值）

多处理器调度的另一个问题是**缓存亲和度**。一个进程在某个CPU上运行时，会在该CPU的缓存中维护许多状态。下次该进程在相同CPU上运行时，由于缓存中的数据而执行得更快。相反，在不同的CPU上执行，会由于需要重新加载数据而很慢。

#### 单队列调度（SQMS）

单队列多处理器调度（SQMS）：简单地复用单处理器调度的基本架构，将所有需要调度的工作放入一个单独的队列中

优点：简单

短板：1. 扩展性差。访问调度队列需要加锁，性能损失大，处理器越多，性能越差。2. 缓存亲和性差

#### 多队列调度（MQMS）

在MQMS中，基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则，比如轮转或其他任何可能的算法。当一个工作进入系统后，系统会依照一些启发性规则（如随机或选择较空的队列）将其放入某个调度队列。这样一来，每个CPU调度之间相互独立，就避免了单队列的方式中由于数据共享及同步带来的问题。

新问题：如何应对负载不均

最明显的答案是让工作移动，这种技术我们称为迁移（migration）。通过工作的跨CPU迁移，可以真正实现负载均衡。

一个基本的方法是采用一种技术，名为**工作窃取**。通过这种方法，工作量较少的（源）队列不定期地“偷看”其他（目标）队列是不是比自己的工作多。如果目标队列比源队列（显著地）更满，就从目标队列“窃取”一个或多个工作，实现负载均衡。

那么间隔多长时间去检查呢？找到合适的阈值仍然是黑魔法，这在系统策略设计中很常见。

#### Linux 多处理器调度

存在3种不同的调度程序：`O(1)`调度程序、完全公平调度程序（`CFS`）以及BF调度程序（`BFS`）

`O(1)` 和 `CFS` 采用多队列，而 `BFS` 采用单队列，这说明两种方法都可以成功。当然它们之间还有很多不同的细节。例如，**O(1)调度程序是基于优先级的（类似于MLFQ）**，随时间推移改变进程的优先级，然后调度最高优先级进程，来实现各种调度目标。交互性得到了特别关注。与之不同，**CFS是确定的比例调度方法（类似于步长调度）**。**BFS作为3个算法中唯一采用单队列的算法，也基于比例调度**，但采用了更复杂的方案，称为最早最合适虚拟截止时间优先算法


## 虚拟化 内存

用户程序生成的每个地址都是虚拟地址。操作系统只是为每个进程提供一个假象，具体来说，就是它拥有自己的大量私有内存。在一些硬件帮助下，操作系统会将这些假的虚拟地址变成真实的物理地址，从而能够找到想要的信息。

### 抽象：地址空间

早期的操作系统内存分配（一次只能运行一个程序）

![](../images/os-memory0.png)

随着多道程序时代的到来，多道程序需要共享内存。

一种实现时分共享的方法，是让一个进程单独占用全部内存运行一小段时间（见图13.1），然后停止它，并将它所有的状态信息保存在磁盘上（包含所有的物理内存），加载其他进程的状态信息，再运行一段时间，这就实现了某种比较粗糙的机器共享。但是**这种方式太慢了**。

因此，在进程切换的时候，我们仍然将进程信息放在内存中，这样操作系统可以更有效率地实现时分共享。每个进程拥有一部分内存。

![](../images/os-memory1.png)

当多道程序同时驻留内存中，使**保护**（protection）成为重要问题。人们不希望一个进程可以读取其他进程的内存，更别说修改了。

因此操作系统需要提供一个易用的物理内存抽象。这个抽象叫作**地址空间**（address space），是运行的程序看到的系统中的内存

一个进程的地址空间包含运行的程序的所有内存状态（代码、静态数据、栈、堆）

> 堆（heap）用于管理动态分配的、用户管理的内存，C语言中调用 `malloc()` 或面向对象语言（如 C++ 或 Java）中调用 `new` 获得内存。

地址空间：

![](../images/os-memory2.png)

**关键问题：如何虚拟化内存**

操作系统如何在单一的物理内存上为多个运行的进程（所有进程共享内存）构建一个私有的、可能很大的地址空间的抽象？

例如当进程A尝试在地址0（虚拟地址）执行加载操作时，然而操作系统在硬件的支持下，出于某种原因，必须确保不是加载到物理地址0，而是物理地址320KB（这是A载入内存的地址）。这是内存虚拟化的关键。

> 隔离是建立可靠系统的关键原则。

虚拟内存系统的设计目标

- **透明**。让运行的程序不感知内存被虚拟化的事实
- **效率**。包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存来支持虚拟化）。为此引入了 TLB 硬件和多级页表设计。
- **保护**。当一个进程执行加载、存储或指令提取时，它不应该以任何方式访问或影响任何其他进程或操作系统本身的内存内容（即在它的地址空间之外的任何内容）

> 作为用户级程序的程序员，可以看到的任何地址都是虚拟地址。只有操作系统（和硬件）才知道物理地址。

### 内存操作 API

对于程序来说，有两种类型的内存。

- 栈（stack）内存，它的申请和释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。
- 堆（heap）内存，其中所有的申请和释放操作都由程序员显式地完成

C 程序通过 `void *malloc(size_t size)` 库函数申请堆内存：传入要申请的堆空间的大小，它成功就返回一个指向新申请空间的指针，失败就返回 NULL

事实证明，分配内存是等式的简单部分。知道何时、如何以及是否释放内存是困难的部分。要释放不再使用的堆内存，程序员只需调用 `free()`：

```c
int *x = malloc(10 * sizeof(int));
...
free(x);
```

!> 调用 free 函数时分配区域的大小不会被用户传入，必须由内存分配库本身记录追踪。

在使用malloc()和free()时会出现一些常见的错误。

1. 忘记分配内存

    ```c
    char *src = "hello";
    char *dst;        // oops! unallocated
    strcpy(dst, src); // segfault and die
    ```

2. 没有分配足够的内存

    ```c
    char *src = "hello";
    char *dst = (char *) malloc(strlen(src)); // too small!
    strcpy(dst, src); // work properly
    ```

3. 忘记初始化分配的内存
4. 忘记释放内存。称为内存泄漏。在这种情况下，当进程死亡时，操作系统才会清理其分配的所有页面

    > 系统中实际存在两级内存管理。第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或以其他方式结束）时将其回收。第二级管理在每个进程中，例如在调用 `malloc()` 和 `free()` 时，在堆内管理。因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题

5. 在用完之前释放内存。这种错误称为悬挂指针。随后的使用可能会导致程序崩溃或覆盖有效的内存（调用了 `free()`，但随后再次调用 `malloc()` 来分配其他内容）
6. 重复释放内存。未定义行为
7. 错误地调用 `free()`。传入一个无效的指针。

`malloc()` 和 `free()` 不是系统调用，而是库调用。malloc库管理虚拟地址空间内的空间，但是它本身是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求更多内存或者将一些内容释放回系统。

一个这样的**系统调用**叫作 `brk`，它被用来改变程序分断（break）的位置：堆结束的位置。它需要一个参数（新分断的地址），从而根据新分断是大于还是小于当前分断，来增加或减小堆的大小。另一个调用 `sbrk` 要求传入一个增量，但目的是类似的。

!> 请注意，你不应该直接调用brk或sbrk。它们被内存分配库使用.

还可以通过 `mmap()` 调用从操作系统获取内存。通过传入正确的参数，`mmap()` 可以在程序中创建一个匿名（anonymous）内存区域——这个区域不与任何特定文件相关联，而是与交换空间（swap space）相关联

另外，内存分配库还支持一些其他调用。例如，`calloc()` 分配内存，并在返回之前将其置零。`realloc()` 创建一个新的更大的内存区域，将旧区域复制到其中，并返回新区域的指针。

### 机制：地址转换

> 关键问题：如何高效、灵活地虚拟化内存

如何实现高效的内存虚拟化？如何提供应用程序所需的灵活性？如何保持控制应用程序可访问的内存位置，从而确保应用程序的内存访问受到合理的限制？如何高效地实现这一切？

我们利用了一种通用技术，有时被称为基于硬件的地址转换，简称为**地址转换**（address translation)。利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写入），将指令中的虚拟地址转换为数据实际存储的物理地址。因此，在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际的位置。

当然，仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。因此它必须管理内存，记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对内存使用的控制。

所有这些工作都是为了创造一种美丽的假象：每个程序都拥有私有的内存，那里存放着它自己的代码和数据。

**介入**是一种很常见又很有用的技术，计算机系统中使用介入常常能带来很好的效果。在虚拟内存中，硬件可以介入到每次内存访问中，将进程提供的虚拟地址转换为数据实际存储的物理地址

假设：
1. 用户的地址空间必须连续地放在物理内存中
2. 地址空间不是很大，具体来说，小于物理内存的大小
3. 每个地址空间的大小完全一样

物理内存和单个重定位的进程:

![](../images/memory-relocate-1.png)

#### 动态（基于硬件）重定位

最初的地址转换：**基址加界限机制**，也称为**动态重定位**

每个 CPU 需要两个硬件寄存器：**基址（base）寄存器**和**界限（bound）寄存器**

采用这种方式，在编写和编译程序时假设地址空间从零开始。但是，当程序真正执行时，操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中。当进程运行时，产生的所有内存引用，都会被处理器通过以下方式转换为物理地址

进程中使用的内存引用都是虚拟地址（virtual address），硬件接下来将虚拟地址加上基址寄存器中的内容，得到物理地址（physical address），再发给内存系统。

在动态重定位的过程中，只有很少的硬件参与，但获得了很好的效果。一个基址寄存器将虚拟地址转换为物理地址，一个界限寄存器确保这个地址在进程地址空间的范围内。

这种基址寄存器配合界限寄存器的硬件结构是芯片中的（每个CPU一对）。有时我们将CPU的这个负责地址转换的部分统称为**内存管理单元**（Memory Management Unit，MMU）。

动态重定位的硬件要求

![](../images/relocate-hardware-required.png)

动态重定位的操作系统职责：

![](../images/relocate-os.png)

受限直接执行协议（动态重定位）:

![](../images/relocate-limit-exec.png)

![](../images/relocate-limit-exec2.png)

这个技术高效的关键是硬件支持，硬件快速地将所有内存访问操作中的虚拟地址（进程自己看到的内存位置）转换为物理地址（实际位置）。所有的这一切对进程来说都是透明的，进程并不知道自己使用的内存引用已经被重定位，制造了美妙的假象。

遗憾的是，这个简单的动态重定位技术有效率低下的问题。由于该进程的栈区和堆区并不很大，导致这块内存区域中大量的空间被浪费。这种浪费通常称为内部碎片，指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。

> 即栈和堆之间，有一大块“空闲”空间。

为了更好地利用物理内存，避免内部碎片。第一次尝试是将基址加界限的概念稍稍泛化，得到**分段**的概念，

### 分段

> 关键问题：怎样支持大地址空间，同时栈和堆之间（可能）有大量空闲空间？

为了解决这个问题，分段的概念应运而生。在 MMU 中引入不止一个基址和界限寄存器对，而是给地址空间内的每个逻辑段一对。一个段只是地址空间里的一个连续定长的区域，在典型的地址空间里有 3 个逻辑不同的段：代码、栈和堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存。

在物理内存中放置段:

![](../images/memory-segment.png)

段寄存器的值

![](../images/segment-reg.png)

如果试图访问非法的地址，会导致段异常（segmentation violation）或段错误（segmentation fault）。

分段地址硬件转换逻辑

```
// get top 2 bits of 14-bit VA
Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
// now get offset
Offset = VirtualAddress & OFFSET_MASK
if (Offset >= Bounds[Segment])
    RaiseException(PROTECTION_FAULT)
else
    PhysAddr = Base[Segment] + Offset
    Register = AccessMemory(PhysAddr)
```

栈是反向增长的，因此转换时还得知道段的增长方向。

分段可以支持共享。要节省内存，有时候在地址空间之间共享（share）某些内存段是有用的。尤其是，**代码共享**很常见。

为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。通过将代码段标记为只读，同样的代码可以被多个进程共享，而不用担心破坏隔离。

![](../images/segment-reg-with-protection.png)

有了保护位，前面描述的硬件算法也必须改变。除了检查虚拟地址是否越界，硬件还需要检查特定访问是否允许。

分段对操作系统提出了新的要求，1. 上下文切换时要保存和恢复各个段寄存器中的内容；2. 管理物理内容的空闲空间

由于段的大小不一，会导致内存的**外部碎片**问题。

该问题的一种解决方案是紧凑（compact）物理内存，重新安排原有的段。整理内存需要占用大量的处理器时间。

一种更简单的做法是利用**空闲列表管理算法**，试图保留大的内存块用于分配。相关的算法可能有成百上千种，包括传统的最优匹配、最坏匹配（worst-fit）、首次匹配以及像伙伴算法这样更复杂的算法。

### 空闲空间管理

如果要管理的空闲空间由大小不同的单元构成，管理就变得困难（而且有趣）。这种情况出现在用户级的内存分配库（如malloc()和free()），或者操作系统用分段（segmentation）的方式实现虚拟内存。

> 关键问题：如何管理空闲空间

要满足变长的分配请求，应该如何管理空闲空间？什么策略可以让碎片最小化？不同方法的时间和空间开销如何？

在堆上管理空闲空间的数据结构通常称为**空闲列表**。该结构包含了管理内存区域中所有空闲块的引用。

#### 追踪已分配空间的大小

`free(void *ptr)` 接口没有块大小的参数。大多数分配程序都会在头块（header）中保存一点额外的信息，它在内存中，通常就在返回的内存块之前

```c++
typedef struct header_t { 
    int size;
    int magic;
} header_t;
```

```c++
void free(void *ptr) {
    header_t *hptr = (void *)ptr - sizeof(header_t);
}
```

获得头块的指针后，库可以很容易地确定幻数是否符合预期的值，作为正常性检查（`assert(hptr->magic == 1234567)`），并简单计算要释放的空间大小（即头块的大小加区域长度）。

![](../images/heap-header.png)

> 因此，如果用户请求N字节的内存，库不是寻找大小为N的空闲块，而是寻找N加上头块大小的空闲块。

#### 嵌入空闲列表

空闲链表节点：

```c++
typedef struct  node_t { 
    int    size;
    struct  node_t *next;
} node_t;
```

堆内存初始化

```c++
// mmap() returns a pointer to a chunk of free space 
node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE,
                   MAP_ANON|MAP_PRIVATE, -1, 0);
head->size    = 4096 - sizeof(node_t); 
head->next    = NULL;
```

![](../images/heap-state0.png)

一次分配后

![](../images/heap-state1.png)

三次分配后

![](../images/heap-state2.png)

一次释放后

![](../images/heap-state3.png)

三次释放后

![](../images/heap-state3.png)

可见空间列表变得非常破碎，解决方案很简单：遍历列表，合并相邻块。

#### 让堆增长

大多数传统的分配程序会从很小的堆开始，当空间耗尽时，再向操作系统申请更大的空间。这意味着它们进行了某种系统调用（例如，大多数UNIX系统中的`sbrk`）

#### 基本策略

理想的分配程序可以同时保证快速和碎片最小化。

- 最优匹配
- 最差匹配
- 首次匹配
- 下次匹配

#### 其它方式

分离空闲列表：如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象。其他大小的请求都交给更通用的内存分配程序。

slab 分配程序采用了分离空闲列表

因为合并对分配程序很关键， 一个好例子就是二分伙伴分配程序（binary buddy allocator）。

### 分页

由于不同长度的分段，会导致内存空间存在碎片化问题。

因此，值得考虑第二种方法：将空间分割成固定长度的分片。在虚拟内存中，我们称这种思想为**分页**。

分页可能最大的改进就是灵活性，另外就是让空闲空间管理更加简单。

> 关键问题：如何通过页来实现虚拟内存

如何通过页来实现虚拟内存，从而避免分段的问题？基本技术是什么？如何让这些技术运行良好，并尽可能减少空间和时间开销？

为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。页表的主要作用是为地址空间的每个虚拟页面保存地址转换（address translation）

![](../images/address-translation.png)

#### 页表存在哪里

页表往往比较大。（一个20位的VPN，假设每个页表条目需要4个字节，那这个页表就需要4MB内存，如果有100个进程，就需要 400MB 内存）

由于比较大，页表只能存储在内存中。


![](../images/page-table-in-memory.png)

#### 页表中究竟有什么

![](../images/x86-pte.png)

P: 存在位（present bit）, 表示该页是在物理存储器还是在磁盘上

R/W: 是否允许写入该页面

U/S: 确定用户模式进程是否可以访问该页面

PWT、PCD、PAT、G：确定硬件缓存如何为这些页面工作

A: 访问位（accessed bit），有时用于追踪页是否被访问，也用于确定哪些页很受欢迎，因此应该保留在内存中

D: 脏位（dirty bit）

#### 分页：也很慢

利用分页访问内存的过程：

```java
// Extract the VPN from the virtual address
VPN = (VirtualAddress & VPN_MASK) >> SHIFT

// Form the address of the page-table entry (PTE)
PTEAddr = PTBR + (VPN * sizeof(PTE))

// Fetch the PTE
PTE = AccessMemory(PTEAddr)

// Check if process can access the page
if (PTE.Valid == False)
    RaiseException(SEGMENTATION_FAULT)
else if (CanAccess(PTE.ProtectBits) == False)
    RaiseException(PROTECTION_FAULT)
else
    // Access is OK: form physical address and fetch it
    offset   = VirtualAddress & OFFSET_MASK
    PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
    Register = AccessMemory(PhysAddr)
```

为了访问 PTE 会多一次内存引用，在这种情况下，可能会使进程减慢两倍或更多。

因此，实现分页需要解决上面两个实际问题

- **会导致较慢的机器（有许多额外的内存访问来访问页表）**
- **内存浪费（内存被页表塞满而不是有用的应用程序数据）**

### 分页：快速地址转换（TLB）

> 关键问题：如何加速地址转换
>
> 如何才能加速虚拟地址转换，尽量避免额外的内存访问？需要什么样的硬件支持？操作系统该如何支持？

想让某些东西更快，操作系统通常需要一些帮助。帮助常常来自操作系统的老朋友：硬件。我们要增加所谓的（由于历史原因）地址转换旁路缓冲存储器（translation-lookaside buffer，TLB），它就是频繁发生的虚拟到物理地址转换的硬件缓存（cache）。因此，更好的名称应该是地址转换缓存（address-translation cache）。对每次内存访问，硬件先检查TLB，看看其中是否有期望的转换映射，如果有，就完成转换（很快），不用访问页表（其中有全部的转换映射）。TLB带来了巨大的性能提升，实际上，因此它使得虚拟内存成为可能。

#### TLB 的基本算法

```java
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
if (Success == True)    // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset   = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
else    // TLB Miss
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else if (CanAccess(PTE.ProtectBits) == False)
        RaiseException(PROTECTION_FAULT)
    else
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
        RetryInstruction()
```

可见性能的提升关键在于**尽可能避免TLB未命中**

缓存的成功依赖于空间和时间局部性。

TLB 的加载单元是PTE，如果页越大，命中率越高。典型页的大小一般为4KB

既然像TLB这样的缓存这么好，为什么不做更大的缓存，装下所有的数据？可惜的是，这里我们遇到了更基本的定律，就像物理定律那样。如果想要快速地缓存，它就必须小，因为光速和其他物理限制会起作用。大的缓存注定慢，因此无法实现目的

#### 谁来处理TLB未命中

可能有两个答案：硬件或软件（操作系统）

现代 RISC 指令计算机一般都是让操作系统来处理。发生TLB未命中时，硬件系统会抛出一个异常，这会暂停当前的指令流，将特权级提升至内核模式，跳转至陷阱处理程序。这个陷阱处理程序是操作系统的一段代码，用于处理TLB未命中。

#### TLB 的内容

典型的TLB有32项、64项或128项，并且是全相联的（这就意味着一条地址映射可能存在TLB中的任意位置，硬件会并行地查找TLB）

格式可能是： `VPN ｜ PFN ｜ 其他位`

常见的其它位：

- 有效位
- 保护位

补充：TLB的有效位!=页表的有效位

在页表中，如果一个页表项（PTE）被标记为无效，就意味着该页并没有被进程申请使用，

TLB的有效位不同，只是指出TLB项是不是有效的地址映射。TLB有效位在系统上下文切换时起到了很重要的作用，通过将所有TLB项设置为无效，系统可以确保将要运行的进程不会错误地使用前一个进程的虚拟到物理地址转换映射。

#### 上下文切换时对TLB的处理

上下文切换时为了避免 TLB 污染，最简单的方法就是清空TLB(把所有条目的有效位置为 0)

但是这样会导致频繁切换进程时，TLB的命中率很低

为了减少这种开销，一些系统增加了硬件支持，实现跨上下文切换的TLB共享。比如有的系统在TLB中添加了一个地址空间标识符（Address Space Identifier，ASID）。可以把ASID看作是进程标识符（Process Identifier，PID），但通常比PID位数少（PID一般32位，ASID一般是8位）

当然，硬件也需要知道当前是哪个进程正在运行，以便进行地址转换，因此操作系统在上下文切换时，必须将某个特权寄存器设置为当前进程的ASID。

#### TLB 替换策略

和其它缓存的策略基本一致，LRU，随机等

#### 实际的 TLB 项

![](../images/mips-tlb.png)

G: 全局位（Global bit），用来指示这个页是不是所有进程全局共享的。因此，如果全局位置为1，就会忽略ASID
ASID: 区分进程空间
C: Coherence 一致位，决定硬件如何缓存该页
D: dirty 脏位，表示该页是否被写入新数据
V: valid 有效位， 告诉硬件该项的地址映射是否有效。

### 分页：较小的表

> 关键问题：如何让页表更小？
>
> 简单的基于数组的页表（通常称为线性页表）太大，在典型系统上占用太多内存。如何让页表更小？关键的思路是什么？由于这些新的数据结构，会出现什么效率影响？

#### 简单的解决方案: 更大的页

这种方法的主要问题在于，大内存页会导致每页内的浪费，这被称为内部碎片（internal fragmentation）问题。所以大多数系统在常见的情况下使用相对较小的页大小：4KB（如x86）或8KB（如SPARCv9）

#### 混合方法：分页和分段

![](../images/seg-and-page.png)

```java
SN           = (VirtualAddress & SEG_MASK) >> SN_SHIFT 
VPN          = (VirtualAddress & VPN_MASK) >> VPN_SHIFT 
AddressOfPTE = Base[SN] + (VPN * sizeof(PTE))
```

杂合方案的关键区别在于，每个分段都有界限寄存器，每个界限寄存器保存了段中最大有效页的值。以这种方式，与线性页表相比，杂合方法实现了显著的内存节省。栈和堆之间未分配的页不再占用页表中的空间（仅将其标记为无效）。

但是，分段并不像我们需要的那样灵活，因为它假定地址空间有一定的使用模式。例如，如果有一个大而稀疏的堆，仍然可能导致大量的页表浪费。其次，这种杂合导致外部碎片再次出现。尽管大部分内存是以页面大小单位管理的，但页表现在可以是任意大小（是PTE的倍数）。

#### 多级页表

另一种方法并不依赖于分段，但也试图解决相同的问题：**如何去掉页表中的所有无效区域，而不是将它们全部保留在内存中？**我们将这种方法称为多级页表

多级页表的基本思想很简单。首先，将页表分成页大小的单元。然后，如果整页的页表项（PTE）无效，就完全不分配该页的页表。为了追踪页表的页是否有效（以及如果有效，它在内存中的位置），使用了名为页目录（page directory）的新结构。页目录因此可以告诉你页表的页在哪里，或者页表的整个页不包含有效页。

![](../images/multi-level-page-table.png)

![](../images/multi-level-virtual-address.png)

多级页表是有成本的，会导致更多的内存访问，因此多级表是一个时间—空间折中的例子。

```java
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
if (Success == True)    // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset   = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
else                  // TLB Miss
    // first, get page directory entry
    PDIndex = (VPN & PD_MASK) >> PD_SHIFT
    PDEAddr = PDBR + (PDIndex * sizeof(PDE))
    PDE     = AccessMemory(PDEAddr)
    if (PDE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else
        // PDE is valid: now fetch PTE from page table
        PTIndex = (VPN & PT_MASK) >> PT_SHIFT
        PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))
        PTE     = AccessMemory(PTEAddr)
        if (PTE.Valid == False)
            RaiseException(SEGMENTATION_FAULT)
        else if (CanAccess(PTE.ProtectBits) == False)
            RaiseException(PROTECTION_FAULT)
        else
            TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
            RetryInstruction()
```

#### 反向页表

在反向页表（inverted page table）中，可以看到页表世界中更极端的空间节省。在这里，我们保留了一个页表，其中的项代表系统的每个物理页，而不是有许多页表（系统的每个进程一个）。页表项告诉我们哪个进程正在使用此页，以及该进程的哪个虚拟页映射到此物理页。

现在，要找到正确的项，就是要搜索这个数据结构。线性扫描是昂贵的，因此通常在此基础结构上建立散列表，以加速查找。

### 超越物理内存：机制

为了支持更大的地址空间，操作系统需要把当前没有在用的那部分地址空间找个地方存储起来。一般来说，这个地方有一个特点，那就是比内存有更大的容量。在现代系统中，硬盘（hard disk drive）通常能够满足这个需求。

#### 交换空间

在硬盘上开辟一部分空间用于物理页的移入和移出。在操作系统中，一般这样的空间称为交换空间（swap space），因为我们将内存中的页交换到其中，并在需要的时候又交换回去。因此，我们会假设操作系统能够以页大小为单元读取或者写入交换空间。为了达到这个目的，操作系统需要记住给定页的硬盘地址（disk address）。

交换空间不是唯一的硬盘交换目的地。二进制程序的代码页本来就是从硬盘上加载的，所以也可以使用硬盘中的二进制文件。

![](../images/disk-memory.png)

硬件（或操作系统，在软件管理TLB时）判断是否在内存中的方法，是通过页表项中的一条新信息，即`存在位（present bit）`。如果存在位为0，则会抛出页错误(page fault)。操作系统被唤起来处理页错误。一段称为“页错误处理程序（page-fault handler）”的代码会执行，来处理页错误

#### 页错误

操作系统可以用PTE中的某些位来存储硬盘地址，这些位通常用来存储像页的PFN这样的数据。当操作系统接收到页错误时，它会在PTE中查找地址，并将请求发送到硬盘，将页读取到内存中。

当硬盘I/O完成时，操作系统会更新页表，将此页标记为存在，更新页表项（PTE）的PFN字段以记录新获取页的内存位置，并重试指令

#### 内存满了怎么办

页交换策略。（和缓存的淘汰策略类似）

#### 页错误处理流程

硬件：

```java
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
(Success, TlbEntry) = TLB_Lookup(VPN)
if (Success == True)    // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset     = VirtualAddress & OFFSET_MASK
        PhysAddr   = (TlbEntry.PFN << SHIFT) | Offset
        Register  = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
else                  // TLB Miss
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else
        if (CanAccess(PTE.ProtectBits) == False)
            RaiseException(PROTECTION_FAULT)
        else if (PTE.Present == True)
            // assuming hardware-managed TLB
            TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
            RetryInstruction()
        else if (PTE.Present == False)
            RaiseException(PAGE_FAULT)
```

操作系统处理页错误

```java
PFN = FindFreePhysicalPage()
if (PFN == -1)               // no free page found
    PFN = EvictPage()        // run replacement algorithm
DiskRead(PTE.DiskAddr, pfn) // sleep (waiting for I/O)
PTE.present = True           // update page table with present
PTE.PFN     = PFN            // bit and translation (PFN)
RetryInstruction()           // retry instruction
```

#### 交换何时真正发生

为了保证有少量的空闲内存，大多数操作系统会设置高水位线（High Watermark，HW）和低水位线（Low Watermark，LW）。当操作系统发现有少于LW个页可用时，后台负责释放内存的线程会开始运行，直到有HW个可用的物理页。这个后台线程有时称为交换守护进程（swap daemon）或页守护进程（page daemon）

### 超越物理内存：策略

> 关键问题：如何决定踢出哪个页
>
> 操作系统如何决定从内存中踢出哪一页（或哪几页）？这个决定由系统的替换策略做出，替换策略通常会遵循一些通用的原则（下面将会讨论），但也会包括一些调整，以避免特殊情况下的行为。

平均内存访问时间计算公式：`AMAT = P(Hit)·T(M) + P(Miss)·T(D)`

现代系统中，磁盘访问的成本非常高，即使很小概率的未命中也会拉低正在运行的程序的总体AMAT

!> 由于分页到硬盘非常昂贵，因此频繁分页的成本太高。所以，过度分页的最佳解决方案往往很简单：购买更多的内存。

#### 最优替换策略

最优策略：替换内存中在最远将来才会被访问到的页，可以达到缓存未命中率最低。

> 为了更好地理解一个特定的替换策略是如何工作的，将它与最好的替换策略进行比较是很好的方法。这样就可以知道你的策略有多大的改进空间，也用于决定当策略已经非常接近最优策略时，停止做无谓的优化。

#### 替换策略

常见的策略有：FIFO，随机，LRU

像LRU这样的算法通常优于简单的策略（如FIFO或随机）。基于历史信息的策略带来了一个新的挑战：应该如何实现呢？

> 关键问题：如何实现LRU替换策略
> 
> 由于实现完美的LRU代价非常昂贵，我们能否实现一个近似的LRU算法，并且依然能够获得预期的效果？

#### 近似 LRU

最简单的是时钟算法

这个想法需要硬件增加一个使用位。

想象一下，系统中的所有页都放在一个循环列表中。时钟指针开始时指向某个特定的页。当必须进行页替换时，操作系统检查当前指向的页P的使用位是1还是0。如果是1，则意味着页面P最近被使用，因此不适合被替换。然后，P的使用位设置为0，时钟指针递增到下一页（P + 1）。该算法一直持续到找到一个使用位为0的页，使用位为0意味着这个页最近没有被使用过（在最坏的情况下，所有的页都已经被使用了，那么就将所有页的使用位都设置为0）。

时间算法还有个变种：在需要进行页替换时`随机`扫描各页，如果遇到一个页的引用位为1，就清除该位（即将它设置为0）。直到找到一个使用位为0的页，将这个页进行替换

> 这个变种的实现更加简单

#### 考虑脏页

如果页已被修改（modified）并因此变脏（dirty），则踢出它就必须将它写回磁盘，这很昂贵。如果它没有被修改，踢出就没成本。

为了支持这种行为，硬件应该包括一个修改位，每次写入页时都会设置此位

时钟算法也要做相应的修改，以扫描既未使用又干净的页先踢出。无法找到这种页时，再查找脏的未使用页面，

#### 其它虚拟内存策略

页面替换不是虚拟内存子系统采用的唯一策略。操作系统还必须决定何时将页载入内存。该策略有时称为页选择（page selection）策略

操作系统可能会猜测一个页面即将被使用，从而提前载入。这种行为被称为`预取`（prefetching）

另一个策略决定了操作系统如何将页面写入磁盘。当然，它们可以简单地一次写出一个。然而，许多系统会在内存中收集一些待完成写入，并以一种（更高效）的写入方式将它们写入硬盘。这种行为通常称为聚集（clustering）写入，或者就是分组写入（grouping）

#### 抖动

当内存就是被超额请求时，操作系统应该做什么，这组正在运行的进程的内存需求是否超出了可用物理内存？在这种情况下，系统将不断地进行换页，这种情况有时被称为抖动

一些早期的操作系统有一组相当复杂的机制，以便在抖动发生时检测并应对。

目前的一些系统采用更严格的方法处理内存过载。例如，当内存超额请求时，某些版本的Linux会运行“内存不足的杀手程序（out-of-memory killer）.这个守护进程选择一个内存密集型进程并杀死它.

### VAX/VMS 虚拟内存系统

VAX/VMS操作系统的虚拟内存管理器，它特别干净漂亮。

VAX-11为每个进程提供了一个32位的虚拟地址空间，分为512字节的页。因此，虚拟地址由23位VPN和9位偏移组成。此外，VPN的高两位用于区分页所在的段。因此，如前所述，该系统是分页和分段的混合体。

由于页大小非常小。系统通过两种方式，减少了页表对内存的压力。

1. 每个进程的地址空间分为两段，P0(代码和堆)，P1(栈)。每段一个页表，和堆之间未使用的地址空间部分不需要页表空间。
2. 通过在内核虚拟内存中放置用户页表。这样内存不够时可以交换到磁盘

将页表放入内核虚拟内存意味着地址转换更加复杂（需要查询系统页表）。幸运的是，VAX的硬件管理的TLB让所有这些工作更快，TLB通常（很有可能）会绕过这种费力的查找。

#### 一个真实的地址空间

研究VMS有一个很好的方面，我们可以看到如何构建一个真正的地址空间

例如代码段永远不会从第0页开始。相反，该页被标记为不可访问，以便为检测空指针（null-pointer）访问提供一些支持

```c
int *p = NULL; // set p = 0
*p = 10;      // try to store value 10 to virtual address 0
```

因此上面的代码会触发段错误

![](../images/vms-address.png)

内核虚拟地址空间（即其数据结构和代码）是每个用户地址空间的一部分。在上下文切换时，操作系统改变P0和P1寄存器以指向即将运行的进程的适当页表。但是，它不会更改S基址和界限寄存器，并因此将“相同的”内核结构映射到每个用户的地址空间。

内核映射到每个地址空间，这种结构使得内核的运转更轻松。例如，如果操作系统收到用户程序（例如，在write()系统调用中）递交的指针，很容易将数据从该指针处复制到它自己的结构。通过这种构造（现在广泛使用），**内核几乎就像应用程序库一样**，尽管是受保护的。

#### 页替换

VAX中的页表项（PTE）包含以下位：一个有效位，一个保护字段（4位），一个修改（或脏位）位，为OS使用保留的字段（5位），最后是一个物理帧号码（PFN）将页面的位置存储在物理内存中。但是：`没有引用位`（no reference bit）！因此，VMS替换算法必须在没有硬件支持的情况下，确定哪些页是活跃的。

开发人员也担心会有`自私贪婪的内存`（memory hog）—— 一些程序占用大量内存，使其他程序难以运行。到目前为止，我们所看到的大部分策略都容易受到这种内存的影响。

为了解决这两个问题，提出了`分段的FIFO`（segmented FIFO）替换策略：每个进程都有一个可以保存在内存中的最大页数，称为`驻留集大小`（Resident Set Size，RSS）。每个页都保存在FIFO列表中。当一个进程超过其RSS时，“先入”的页被驱逐。

正如我们前面看到的，纯粹的FIFO并不是特别好。为了提高FIFO的性能，VMS引入了两个`二次机会列表`，页在从内存中被踢出之前被放在其中。具体来说，是全局的干净页空闲列表和脏页列表。当进程P超过其RSS时，将从其进程的FIFO中移除一个页。如果干净（未修改），则将其放在干净页列表的末尾。如果脏（已修改），则将其放在脏页列表的末尾。

如果另一个进程Q需要一个空闲页，它会从全局干净列表中取出第一个空闲页。但是，如果原来的进程P在回收之前在该页上出现页错误，则P会从空闲（或脏）列表中回收，从而避免昂贵的磁盘访问。**这些全局二次机会列表越大，分段的FIFO算法越接近LRU**。

#### 页聚集

VMS采用的另一个优化也有助于克服VMS中的小页面问题。通过聚集，VMS将大批量的页从全局脏列表中分组到一起，并将它们一举写入磁盘

#### 其它漂亮的虚拟内存技巧

VMS有另外两个现在成为标准的技巧：按需置零和写入时复制。

> 都是些惰性优化手段

利用按需置零，当页添加到你的地址空间时，操作系统的工作很少。它会在页表中放入一个标记页不可访问的条目。如果进程读取或写入页，则会向操作系统发送陷阱。此时，操作系统会完成寻找物理页的必要工作，将它置零，并映射到进程的地址空间。如果该进程从不访问该页，则所有这些工作都可以避免，从而体现按需置零的好处。

写时复制: 如果操作系统需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为只读。如果其中一个地址空间确实尝试写入页面，就会陷入操作系统.操作系统会注意到该页面是一个COW页面，因此（惰性地）分配一个新页，填充数据，并将这个新页映射到错误处理的地址空间

## 并发

### 并发介绍

### 插叙：线程 API

### 锁

### 基于锁的并发数据结构

### 条件变量

### 信号量

### 常见并发问题

### 基于事件的并发（进阶）